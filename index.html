<!DOCTYPE html>
<html>
<head>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css">
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js"></script>
  <script>
    
    window.addEventListener('DOMContentLoaded', function () {
      const root = document.getElementById('method');
      if (!root) return;
      renderMathInElement(root, {
        delimiters: [
          {left: '$$',  right: '$$',  display: true},
          {left: '\\[', right: '\\]', display: true},
          {left: '\\(', right: '\\)', display: false}
        ],
        
        macros: {
          "\\alphac": "{\\color{#6A5AE0}{\\alpha}}",
          "\\betac":  "{\\color{#6A5AE0}{\\beta}}",
          "\\gammac": "{\\color{#6A5AE0}{\\gamma}}"
        },
        throwOnError: false
      });
    });
  </script>
  <meta charset="utf-8">
  <meta name="description"
        content="SECOND: Mitigating Perceptual Hallucination in Vision-Language Models via Selective and Contrastive Decoding">
  <meta name="keywords" content="Second, Vision-Language Model, Hallucination, Selective Decoding, Contrastive Decoding"> 
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- Paper title -->
  <title>SECOND: Mitigating Perceptual Hallucination in Vision-Language Models via Selective and Contrastive Decoding</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.ico">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <style>
    
    tr.block-head { background: #f7f7fb; }
  
    
    .best { background: #e8e1ff !important; }
  
  
    td.cd-yes { font-weight: 700; }
    td.cd-no { opacity: 0.65; }
  </style>

  <!-- Gradio -->
  <script
	  type="module"
	  src="https://gradio.s3-us-west-2.amazonaws.com/5.42.0/gradio.js"
  ></script>
</head>
<body>

<!-- Navbar -->
<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://aidas.snu.ac.kr">
        <span class="icon">
            <i class="fas fa-home"></i>
        </span>
        <div style="padding-left:5px;">AIDAS Lab</div>
      </a>
    </div>
  </div>
</nav>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <!-- Paper Title -->
          <!DOCTYPE html>
          <html lang="en">
          <head>
            <meta charset="UTF-8">
            <title>Test Gradient</title>
            <style>
              .gradient-text {
                font-weight: 900;
                background: linear-gradient(90deg, #4facfe, #9b59b6); /* 블루 → 퍼플 */
                -webkit-background-clip: text;
                -webkit-text-fill-color: transparent;
                color: transparent; /* 이거 안 넣으면 일부 브라우저에서 안 보임 */
                display: inline-block; /* Safari 대응 */
              }
          
              .publication-title {
                margin-top: 40px;
              }
            </style>
          </head>
          <body>
            <h1 class="title is-1 publication-title">
              <span class="gradient-text">SECOND</span>: Mitigating Perceptual Hallucination in Vision-Language Models via Selective and Contrastive Decoding
            </h1>
          </body>
          </html>

          <!-- Conference Name and Year -->
          <h1 class="title is-4 publication-title" style="color: #FF0066;">
            ICML 2025
          </h1>

          <!-- Authors and Affiliations -->
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://...">Woohyeon Park</a><sup>1</sup>,
            <span class="author-block">
              <a href="https://...">Woojin Kim</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://...">Jaeik Kim</a><sup>1</sup>,</span>
            </span>
            <span class="author-block">
              <a href="http://...">Jaeyoung Do</a><sup>1</sup>,
            </span>
            <!-- <span class="author-block">
              <a href="https://...">Author5</a><sup>1,2</sup>
            </span> -->
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Seoul National University,</span>
            <!-- <span class="author-block"><sup>2</sup>Microsoft Research</span> -->
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- Paper Link. -->
              <span class="link-block">
                <a href="https://icml.cc/virtual/2025/poster/45215"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Arxiv Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2506.08391"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/AIDASLab/SECOND"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- main image -->
      <figure class="image">
        <img src="./static/images/SECOND_MAIN.png"
             alt="subtitle of the main image">
      </figure>
      <h2 class="subtitle has-text-centered" style="margin-top: 20px;">
        Architecture of <span class="gradient-text">SECOND</span>
      </h2>
    </div>
  </div>
</section>


<!-- Paper abstract -->
<section class="hero is-light ">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Abstract</h2>
          <div class="column has-text-justified" style="padding: 0;">
            <p>
              Despite significant advancements in Vision-Language Models (VLMs), the performance of existing VLMs remains hindered by object hallucination, a critical challenge to achieving accurate visual understanding. To address this issue, we propose <span class="gradient-text">SECOND</span>: Selective and Contrastive Decoding, a novel approach that enables VLMs to effectively leverage multi-scale visual information with an object-centric manner, closely aligning with human visual perception. 
            </p>
            <p>
              <span class="gradient-text">SECOND</span> progressively selects and integrates multi-scale visual information, facilitating a more precise interpretation of images. By contrasting these visual information iteratively, <span class="gradient-text">SECOND</span> significantly reduces perceptual hallucinations and outperforms a wide range of benchmarks. Our theoretical analysis and experiments highlight the largely unexplored potential of multi-scale application in VLMs, showing that prioritizing and contrasting across scales outperforms existing methods.
            </p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section" id="motivation">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Motivation</h2>

        <div class="content has-text-justified">
          <p>

            <figure class="image has-text-centered" style="margin: 32px auto 0; max-width: 820px;">
              <img
                src="./static/images/ICML 2025 Figure 1-1.png"
                alt="Comparison of patch usage between baseline VLM and SECOND"
                style="width:50%; height:auto; border-radius:12px; box-shadow:0 6px 20px rgba(0,0,0,0.12);"
              >
              <figcaption class="has-text-centered" style="margin-top: 10px; font-size: 0.95rem; color:#555;">
                Figure 1. Unlike uniform patch usage in baselines, 
                <span class="gradient-text">SECOND</span>  selectively accumulates object-relevant patches 
                while suppressing background noise.
              </figcaption>
            </figure>
          </p>
          <p>
            VLMs often suffer from <strong>perceptual hallucination</strong>, 
            mainly because they <em>uniformly integrate multi-scale patches</em>, 
            mixing object signals with background noise. 
            Inspired by human coarse-to-fine perception, 
            <span class="gradient-text">SECOND</span> tackles this by 
            <strong>selectively</strong> keeping salient patches 
            and enforcing <strong>contrastive consistency</strong> 
            between coarse and fine stages.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Method -->
<section class="section" id="method">
  <style>
    :root { --accent: #6A5AE0; } /* 원하는 색으로 교체 */
    .accent { color: var(--accent); font-weight: 700; }
  </style>
  <script>
    document.addEventListener('DOMContentLoaded', () => {
      
      setTimeout(() => {
        const root = document.querySelector('#method');
        if (!root) return;
        const walker = document.createTreeWalker(root, NodeFilter.SHOW_TEXT);
        const targets = [];
        while (walker.nextNode()) {
          const n = walker.currentNode;
          
          if (n.parentElement.closest('.katex, .katex-display, .katex-html, script, style, code, pre')) continue;
          if (n.nodeValue.includes('SECOND')) targets.push(n);
        }
        for (const n of targets) {
          const span = document.createElement('span');
          
          span.innerHTML = n.nodeValue.replace(/SECOND/g, '<span class="gradient-text">SECOND</span>');
          n.parentNode.replaceChild(span, n);
        }
      }, 0);
    });
    </script>
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Method</h2>

        <div class="content has-text-justified">
          <p>
            <strong>SECOND</strong> (Selective and Contrastive Decoding) is a 
            training-free multi-stage framework designed to mitigate perceptual hallucinations 
            in Vision-Language Models (VLMs). SECOND combines 
            <em>selective multi-scale feature integration</em> with 
            <em>multi-stage contrastive decoding</em> to progressively refine object-centric 
            representations and suppress hallucinated outputs.
          </p>

          <h4 class="title is-5" style="margin-top:1.25rem;">1. Selective Multi-Scale Feature Integration</h4>
          <p>
            SECOND constructs a <em>multi-stage visual hierarchy</em> by progressively expanding 
            resolution from coarse to fine. At stage \(s\), the set of patches 
            \( \mathcal{P}^{(s)} \) is selected based on an entropy-guided rule:
          </p>
          <p style="text-align:center;">
            \( p_{\text{select}} = \frac{\exp(\lambda \cdot H(V)) - 1}{\exp(\lambda) - 1}, \)
          </p>
          <p>
            where \(H(V)\) is the entropy of the visual attention distribution, and \(\lambda\) 
            is a scaling hyperparameter. Patches with the top \(p_{\text{select}}\%\) attention 
            scores are retained for the next stage, ensuring that object-relevant regions are 
            progressively emphasized while background noise is suppressed.
          </p>

          <h4 class="title is-5" style="margin-top:1.25rem;">2. Multi-Stage Contrastive Decoding</h4>
          <p>
            Building on the hierarchy of outputs, SECOND introduces <em>multi-stage contrastive decoding</em>.
            Standard Contrastive Decoding contrasts an expert output with a single amateur:
          </p>
          <p style="text-align:center;">
            \( \text{logit}_{\text{single}} = \text{logit}_{\text{expert}} 
            + \alpha(\text{logit}_{\text{expert}} - \text{logit}_{\text{amateur}}). \)
          </p>
          <p>
            SECOND generalizes this into a multi-stage setting, leveraging all intermediate 
            “amateur” outputs. For a 4-stage setup:
          </p>
          <div id="method" style="text-align:center;">
            $$
            \text{logit}_{\text{SECOND}} =
            \text{logit}_{\text{expert}}
            + \alphac\!\big(\text{logit}_{\text{expert}}-\text{logit}_{\text{amateur3}}\big)
            + \betac\!\big(\text{logit}_{\text{amateur3}}-\text{logit}_{\text{amateur2}}\big)
            + \gammac\!\big(\text{logit}_{\text{amateur2}}-\text{logit}_{\text{amateur1}}\big).
            $$
          </div>
          <p>
            This hierarchical contrast exploits the progressive refinement of patch selection, 
            amplifying consistent object evidence while canceling out hallucinated signals 
            from earlier stages.
          </p>


        <!-- Method Diagram -->
        <figure class="image has-text-centered" style="margin: 40px auto 0; max-width: 860px;">
          <img
            src="./static/images/VIS_ATTN.png"
            alt="SECOND pipeline: stage-wise patch selection (coarse→fine) and multi-stage contrastive decoding"
            style="width:100%; height:auto; border-radius:12px; box-shadow:0 6px 24px rgba(0,0,0,0.12);"
          >
          <figcaption class="has-text-centered" style="margin-top: 12px; font-size: 0.95rem; color:#555;">
            Figure 2. The <em>SECOND</em> pipeline — entropy-guided patch selection across 
            stages (coarse→fine), followed by hierarchical contrastive decoding of amateur 
            and expert outputs.
          </figcaption>
        </figure>
      </div>
    </div>
  </div>
</section>


<!-- Results -->
<section class="section" id="results">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Main Results</h2>

        <div class="content has-text-justified">
          <p>
            We report main results on the <strong>POPE</strong> hallucination benchmark, comparing 
            <span class="gradient-text">SECOND</span> with baselines and VCD across multiple VLM backbones (LLaVA-Next, 
            LLaVA-OneVision, Yi-VL) and LLMs (Vicuna-7B, Mistral-7B, Qwen2-0.5B, Yi-6B). 
            <span class="gradient-text">SECOND</span> consistently outperforms prior methods, achieving <strong>11 out of 12 wins</strong>, 
            with substantial gains in recall, accuracy, and F1. These improvements demonstrate 
            <span class="gradient-text">SECOND</span>’s effectiveness in mitigating perceptual hallucination while preserving reasoning ability.
          </p>

          <!-- results table -->
          <div class="table-container" style="margin-top: 2rem;">
            <table class="table is-striped is-hoverable is-fullwidth has-text-centered"
                   style="border-radius: 12px; overflow: hidden; box-shadow: 0 4px 18px rgba(0,0,0,0.08); font-size: 0.85rem;">
              <thead style="background: linear-gradient(90deg, #4facfe, #9b59b6); color: white;">
                <tr>
                  <th rowspan="2" style="vertical-align: middle;">Model</th>
                  <th rowspan="2">LLM</th>
                  <th rowspan="2">Method</th>
                  <th rowspan="2">CD</th>
                  <th colspan="3">MSCOCO</th>
                  <th colspan="3">OKVQA</th>
                  <th colspan="3">GQA</th>
                </tr>
                <tr>
                  <th>Recall</th><th>Acc.</th><th>F1</th>
                  <th>Recall</th><th>Acc.</th><th>F1</th>
                  <th>Recall</th><th>Acc.</th><th>F1</th>
                </tr>
              </thead>
              <tbody>
                <!-- LLaVA-Next Vicuna-7B -->
                <tr class="has-background-light"><th rowspan="4">LLaVA-Next<br>(CLIP-336)</th><td rowspan="4">Vicuna-7B</td>
                  <td>baseline</td><td>✗</td><td>78.8</td><td>87.7</td><td>86.5</td><td>86.7</td><td>89.1</td><td>88.8</td><td>84.8</td><td>86.6</td><td>86.3</td></tr>
                <tr><td>VCD</td><td>✓</td><td>81.1</td><td>88.2</td><td>87.3</td><td>88.3</td><td>88.0</td><td>88.1</td><td>86.3</td><td>84.6</td><td>84.9</td></tr>
                <tr><td>SECOND</td><td>✗</td><td>80.1</td><td>88.6</td><td>87.5</td><td>87.6</td><td>89.9</td><td>89.6</td><td>84.9</td><td>86.5</td><td>86.3</td></tr>
                <tr style="background-color:#f4f0ff;"><td><strong>SECOND</strong></td><td>✓</td><td><strong>85.1</strong></td><td><strong>89.7</strong></td>
                  <td style="background:#e8e1ff;"><strong>89.2</strong></td>
                  <td><strong>90.5</strong></td><td><strong>90.3</strong></td>
                  <td style="background:#e8e1ff;"><strong>90.4</strong></td>
                  <td><strong>85.5</strong></td><td><strong>89.4</strong></td>
                  <td style="background:#e8e1ff;"><strong>87.4</strong></td></tr>

                <!-- LLaVA-Next Mistral-7B -->
                <tr class="has-background-light"><th rowspan="4">LLaVA-Next<br>(CLIP-336)</th><td rowspan="4">Mistral-7B</td>
                  <td>baseline</td><td>✗</td><td>80.2</td><td>88.3</td><td>87.3</td><td>88.2</td><td>88.7</td><td>88.7</td><td>88.2</td><td>84.2</td><td>84.8</td></tr>
                <tr><td>VCD</td><td>✓</td><td>80.8</td><td>87.4</td><td>86.6</td><td>88.0</td><td>88.2</td><td>88.3</td><td>88.0</td><td>84.5</td><td>85.1</td></tr>
                <tr><td>SECOND</td><td>✗</td><td>79.5</td><td>88.1</td><td>86.9</td><td>86.8</td><td>88.4</td><td>88.2</td><td>87.2</td><td>84.8</td><td>85.2</td></tr>
                <tr style="background-color:#f4f0ff;"><td><strong>SECOND</strong></td><td>✓</td><td><strong>84.8</strong></td><td><strong>89.3</strong></td>
                  <td style="background:#e8e1ff;"><strong>88.8</strong></td>
                  <td><strong>92.5</strong></td><td><strong>89.9</strong></td>
                  <td style="background:#e8e1ff;"><strong>90.7</strong></td>
                  <td><strong>92.1</strong></td><td><strong>85.3</strong></td>
                  <td style="background:#e8e1ff;"><strong>87.5</strong></td></tr>

                <!-- LLaVA-OneVision -->
                <tr class="has-background-light"><th rowspan="4">LLaVA-OneVision<br>(SigLIP-384)</th><td rowspan="4">Qwen2-0.5B</td>
                  <td>baseline</td><td>✗</td><td>80.0</td><td>88.4</td><td style="background:#e8e1ff;"><strong>87.4</strong></td>
                  <td>85.6</td><td>89.3</td><td>88.9</td><td>83.1</td><td>86.8</td><td>86.3</td></tr>
                <tr><td>VCD</td><td>✓</td><td>79.7</td><td>87.4</td><td>86.4</td><td>86.7</td><td>89.0</td><td>88.7</td><td>84.3</td><td>86.7</td><td>86.4</td></tr>
                <tr><td>SECOND</td><td>✗</td><td>78.1</td><td>87.6</td><td>86.3</td><td>83.8</td><td>88.7</td><td>88.1</td><td>82.2</td><td>87.4</td><td>86.7</td></tr>
                <tr style="background-color:#f4f0ff;"><td><strong>SECOND</strong></td><td>✓</td><td>79.7</td><td>87.9</td><td>86.9</td><td>85.4</td><td>89.3</td>
                  <td style="background:#e8e1ff;"><strong>89.1</strong></td>
                  <td>83.3</td><td>87.8</td><td style="background:#e8e1ff;"><strong>87.2</strong></td></tr>

                <!-- Yi-VL -->
                <tr class="has-background-light"><th rowspan="4">Yi-VL<br>(CLIP-448)</th><td rowspan="4">Yi-6B</td>
                  <td>baseline</td><td>✗</td><td>70.3</td><td>82.0</td><td>79.6</td><td>77.0</td><td>84.0</td><td>82.8</td><td>74.5</td><td>81.0</td><td>79.7</td></tr>
                <tr><td>VCD</td><td>✓</td><td>73.0</td><td>80.1</td><td>78.6</td><td>79.1</td><td>82.1</td><td>81.6</td><td>78.2</td><td>79.9</td><td>79.5</td></tr>
                <tr><td>SECOND</td><td>✗</td><td>73.5</td><td>83.5</td><td>82.0</td><td>80.1</td><td>85.6</td><td>84.8</td><td>76.6</td><td>82.5</td><td>81.4</td></tr>
                <tr style="background-color:#f4f0ff;"><td><strong>SECOND</strong></td><td>✓</td><td><strong>83.4</strong></td><td><strong>84.5</strong></td>
                  <td style="background:#e8e1ff;"><strong>84.3</strong></td>
                  <td><strong>87.7</strong></td><td><strong>86.3</strong></td>
                  <td style="background:#e8e1ff;"><strong>86.5</strong></td>
                  <td><strong>83.3</strong></td><td><strong>82.8</strong></td>
                  <td style="background:#e8e1ff;"><strong>82.9</strong></td></tr>
              </tbody>
              <tfoot>
                <tr>
                  <td colspan="13" class="has-text-grey is-size-6">
                    Higher is better for Recall / Accuracy / F1. <span class="gradient-text">SECOND</span> achieved the best results in 11 of 12 cases.
                  </td>
                </tr>
              </tfoot>
            </table>
          </div>

          <p class="has-text-centered is-size-6 has-text-grey" style="margin-top:1rem;">
            <em>Table&nbsp;1. Results of POPE benchmark. <span class="gradient-text">SECOND</span> consistently outperforms baselines and VCD across multiple backbones.</em>
          </p>

          <p class="has-text-grey-darker" style="margin-top:1rem;">
            <strong>Beyond POPE.</strong>
            On general VQA benchmarks including VQAv2(lite), MMStar, and MMBench(lite),
            <span class="gradient-text">SECOND</span>(+CD) consistently achieves strong performance across diverse backbones and LLMs,
            further demonstrating its effectiveness beyond hallucination-specific evaluation.
          </p>

          <!-- Additional Results: VQAv2(lite), MMStar, MMBench(lite) -->
          <div class="table-container" style="margin-top: 2rem;">
            <table class="table is-striped is-hoverable is-fullwidth has-text-centered"
                  style="border-radius: 12px; overflow: hidden; box-shadow: 0 4px 18px rgba(0,0,0,0.08); font-size: 0.85rem;">
              <thead style="background: linear-gradient(90deg, #4facfe, #9b59b6); color: white;">
                <tr>
                  <th>Model</th>
                  <th>LLM</th>
                  <th>Method</th>
                  <th>CD</th>
                  <th>VQAv2 (lite)</th>
                  <th>MMStar</th>
                  <th>MMBench (lite)</th>
                </tr>
              </thead>
              <tbody>
                <!-- LLaVA-Next (CLIP-336) — Vicuna-7B -->
                <tr class="has-background-light">
                  <th rowspan="4">LLaVA-Next<br>(CLIP-336)</th>
                  <td rowspan="4">Vicuna-7B</td>
                  <td>baseline</td><td>✗</td><td>76.4</td><td>37.3</td><td>75.8</td>
                </tr>
                <tr>
                  <td>VCD</td><td>✓</td><td>72.9</td><td>38.1</td><td>74.2</td>
                </tr>
                <tr>
                  <td>SECOND</td><td>✗</td><td>76.5</td><td>37.5</td><td>78.0</td>
                </tr>
                <tr style="background-color:#f4f0ff;">
                  <td><strong>SECOND</strong></td><td>✓</td>
                  <td style="background:#e8e1ff;"><strong>77.5</strong></td>
                  <td style="background:#e8e1ff;"><strong>38.6</strong></td>
                  <td style="background:#e8e1ff;"><strong>80.0</strong></td>
                </tr>

                <!-- LLaVA-Next (CLIP-336) — Mistral-7B -->
                <tr class="has-background-light">
                  <th rowspan="4">LLaVA-Next<br>(CLIP-336)</th>
                  <td rowspan="4">Mistral-7B</td>
                  <td>baseline</td><td>✗</td><td>72.0</td><td>32.4</td>
                  <td style="background:#e8e1ff;"><strong>74.2</strong></td>
                </tr>
                <tr>
                  <td>VCD</td><td>✓</td><td>70.1</td><td>34.0</td><td>71.2</td>
                </tr>
                <tr>
                  <td>SECOND</td><td>✗</td><td>73.6</td><td>34.1</td><td>71.2</td>
                </tr>
                <tr style="background-color:#f4f0ff;">
                  <td><strong>SECOND</strong></td><td>✓</td>
                  <td style="background:#e8e1ff;"><strong>74.5</strong></td>
                  <td style="background:#e8e1ff;"><strong>36.2</strong></td>
                  <td>70.5</td>
                </tr>

                <!-- LLaVA-OneVision (SigLIP-384) — Qwen2-0.5B -->
                <tr class="has-background-light">
                  <th rowspan="4">LLaVA-OneVision<br>(SigLIP-384)</th>
                  <td rowspan="4">Qwen2-0.5B</td>
                  <td>baseline</td><td>✗</td>
                  <td>74.6</td><td>38.9</td>
                  <td style="background:#e8e1ff;"><strong>73.5</strong></td>
                </tr>
                <tr>
                  <td>VCD</td><td>✓</td><td>55.0</td><td>36.2</td><td>70.5</td>
                </tr>
                <tr>
                  <td>SECOND</td><td>✗</td><td>73.6</td><td>39.6</td><td>72.7</td>
                </tr>
                <tr style="background-color:#f4f0ff;">
                  <td><strong>SECOND</strong></td><td>✓</td>
                  <td style="background:#e8e1ff;"><strong>75.1</strong></td>
                  <td style="background:#e8e1ff;"><strong>39.9</strong></td>
                  <td style="background:#e8e1ff;"><strong>73.5</strong></td>
                </tr>

                <!-- Yi-VL (CLIP-448) — Yi-6B -->
                <tr class="has-background-light">
                  <th rowspan="4">Yi-VL<br>(CLIP-448)</th>
                  <td rowspan="4">Yi-6B</td>
                  <td>baseline</td><td>✗</td><td>64.3</td><td>34.8</td><td>77.3</td>
                </tr>
                <tr>
                  <td>VCD</td><td>✓</td><td>61.9</td><td>34.4</td><td>79.5</td>
                </tr>
                <tr>
                  <td>SECOND</td><td>✗</td><td>63.6</td><td>37.4</td><td>82.6</td>
                </tr>
                <tr style="background-color:#f4f0ff;">
                  <td><strong>SECOND</strong></td><td>✓</td>
                  <td style="background:#e8e1ff;"><strong>65.3</strong></td>
                  <td style="background:#e8e1ff;"><strong>39.8</strong></td>
                  <td style="background:#e8e1ff;"><strong>84.8</strong></td>
                </tr>
              </tbody>
              <tfoot>
                <tr>
                  <td colspan="7" class="has-text-grey is-size-6">
                    Higher is better. Best numbers within each backbone–LLM block are highlighted.
                  </td>
                </tr>
              </tfoot>
            </table>
</div>

          <p class="has-text-centered is-size-6 has-text-grey" style="margin-top:1rem;">
            <em>Table&nbsp;2. Results on VQAv2(lite), MMStar, and MMBench(lite).</em>
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- BibTeX -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{park2025second,
      title     = {SECOND: Mitigating Perceptual Hallucination in Vision-Language Models via Selective and Contrastive Decoding},
      author    = {Park, Woohyeon and Kim, Woojin and Kim, Jaeik and Do, Jaeyoung},
      booktitle = {Proceedings of the 42nd International Conference on Machine Learning (ICML)},
      year      = {2025},
      series    = {Proceedings of Machine Learning Research},
      publisher = {PMLR}
    }</code></pre>
  </div>
</section>

<!-- Footer (Don't change) -->
<footer class="footer" style="padding-bottom: 40px;">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is adapted from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>, licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
        <div class="content has-text-centered">
          <a href="https://en.snu.ac.kr">
            <img src="./static/images/snu_logo.png" alt="Logo" style="max-height: 48px; margin: 6px 10px;">
          </a>
          <a href="https://aidas.snu.ac.kr">
            <img src="./static/images/aidaslab_logo.png" alt="Logo" style="max-height: 36px; margin: 10px 30px;">
          </a>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>


</html>
